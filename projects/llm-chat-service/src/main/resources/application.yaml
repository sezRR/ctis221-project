spring:
  application:
    name: llm-chat-service
  autoconfigure:
    exclude:
      - org.springframework.ai.model.chat.client.autoconfigure.ChatClientAutoConfiguration
  data:
    redis:
      host: redis
      port: 6379
  jpa:
    generate-ddl: true
    show-sql: true
    hibernate:
      ddl-auto: update
  ai:
    chat:
      memory:
        repository:
          jdbc:
            initialize-schema: false
    ollama:
      chat:
        model: llama3.2
    openai:
      api-key: ${OPENROUTER_API_KEY}
      base-url: https://openrouter.ai/api
      chat:
        options:
          model: google/gemma-3-12b-it:free # fallback
          
openrouter:
  models:
    - google/gemma-3-12b-it:free
    - microsoft/phi-4-reasoning-plus:free
    - nousresearch/deephermes-3-mistral-24b-preview:free
    - qwen/qwen3-0.6b-04-28:free
    - qwen/qwen3-1.7b:free
    - qwen/qwen3-4b:free
    - openai/gpt-4.1-nano
    - google/gemini-2.0-flash-001

server:
  port: 8080
  servlet:
      context-path: /api
  
app:
  keycloak:
    admin:
      clientId: admin-cli
      clientSecret: ${KEYCLOAK_CLIENT_SECRET}
    realm: llm-chat-wrapper
    serverUrl: http://keycloak:9082