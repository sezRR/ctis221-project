spring:
  application:
    name: llm-chat-service
  data:
    redis:
      host: redis
      port: 6379
  jpa:
    generate-ddl: true
    show-sql: true
    hibernate:
      ddl-auto: update
  ai:
    chat:
      memory:
        repository:
          jdbc:
            initialize-schema: false
    ollama:
      chat:
        model: llama3.2

server:
  port: 8080
  servlet:
      context-path: /api
  
app:
  keycloak:
    admin:
      clientId: admin-cli
      clientSecret: ${KEYCLOAK_CLIENT_SECRET}
    realm: llm-chat-wrapper
    serverUrl: http://keycloak:9082